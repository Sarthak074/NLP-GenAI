{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC_0-D4pfqQP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name=\"xlm-roberta-large\", num_labels=5):\n",
        "    \"\"\"Loads the XLM-RoBERTa model and tokenizer for sentiment analysis.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "    return tokenizer, model"
      ],
      "metadata": {
        "id": "vqtKbPxOgPZv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_label(sentiment):\n",
        "    \"\"\"Maps numerical sentiment prediction to a textual label.\"\"\"\n",
        "    labels = {\n",
        "        0: \"Very Negative\",\n",
        "        1: \"Negative\",\n",
        "        2: \"Neutral\",\n",
        "        3: \"Positive\",\n",
        "        4: \"Very Positive\"\n",
        "    }\n",
        "    return labels.get(sentiment, \"Unknown\")"
      ],
      "metadata": {
        "id": "H3tiObbJhOYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text, tokenizer, model):\n",
        "    \"\"\"Predicts sentiment for a given text using the XLM-R model.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    scores = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    sentiment = torch.argmax(scores, dim=-1).item()\n",
        "    sentiment_label = get_sentiment_label(sentiment)\n",
        "    return sentiment, sentiment_label, scores.tolist()"
      ],
      "metadata": {
        "id": "ZE7d35oLgRnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    tokenizer, model = load_model()\n",
        "    text = \"I love working on AI projects!\"\n",
        "    sentiment, sentiment_label, scores = predict_sentiment(text, tokenizer, model)\n",
        "    print(f\"Predicted Sentiment: {sentiment} ({sentiment_label})\")\n",
        "    print(f\"Confidence Scores: {scores}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcXkaadfgVfj",
        "outputId": "29cece45-8790-4fd6-da32-105d07849ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Sentiment: 4 (Very Positive)\n",
            "Confidence Scores: [[0.13152866065502167, 0.23357628285884857, 0.180240198969841, 0.18806177377700806, 0.2665930688381195]]\n"
          ]
        }
      ]
    }
  ]
}